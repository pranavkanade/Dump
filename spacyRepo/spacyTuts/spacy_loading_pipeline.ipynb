{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ''nlp\" is type of  \"spacy.en.English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"twice\")\n",
    "# print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twice ADV RB twice (300,)\n"
     ]
    }
   ],
   "source": [
    "for w in doc:\n",
    "    print(w.text, w.pos_, w.tag_, w.lemma_, w.vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "doc = nlp.make_doc(text)\n",
    "\n",
    "for proc in nlp.pipeline:\n",
    "    proc(doc)\n",
    "    \n",
    "nlp.pipeline  => {  doc = nlp.tokenizer(t),\\n\n",
    "                    nlp.tagger(doc),\\n\n",
    "                    nlp.parser(doc),\\n\n",
    "                    nlp.entity(doc) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreaded Pipe\n",
    "for sequence of documents use multithreading  \n",
    "### nlp.pipe(texts, batch_size=1000, n_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos and tags \n",
    "https://spacy.io/docs/usage/pos-tagging\n",
    "\n",
    "Entity types https://spacy.io/docs/usage/entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(doc.vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_1 = nlp(\"thrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73638170770354938"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.similarity(doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thrice'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1[0].is_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_2 = nlp(\"Joshua told his friend that his sister is nine years older than himself. If Joshua is nine at the moment, how old is his sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob1 = \"After digging in his backyard, John found seven coins for his collection. If he already had nine coins, how many coins did John have after the new ones?\"\n",
    "doc_1 = nlp(prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = []\n",
    "for span in doc_1.sents:\n",
    "    sent = ''.join(doc_1[i].string \n",
    "                   for i in range(span.start, span.end)).strip()\n",
    "    sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After digging in his backyard, John found seven coins for his collection.\n",
      "If he already had nine coins, how many coins did John have after the new ones?\n"
     ]
    }
   ],
   "source": [
    "for sentence in sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence tokenizing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After digging in his backyard, John found seven coins for his collection.\n",
      "If he already had nine coins, how many coins did John have after the new ones?\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_tokenize(prob1):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out droping all the nouns in the prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob1_without_noun = []\n",
    "\n",
    "for token in doc_1:\n",
    "    if (token.pos_ not in [\"NOUN\", \"PROPN\", \"DET\", \"PUNCT\", \"PRON\"]) and (token.tag_ not in [\"PRP$\", \"WP$\"]):\n",
    "        prob1_without_noun.append(token.orth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After', 'digging', 'in', 'found', 'seven', 'for', 'If', 'already', 'had', 'nine', 'how', 'many', 'did', 'have', 'after', 'new']\n"
     ]
    }
   ],
   "source": [
    "print(prob1_without_noun)\n",
    "string = \"After digging in his backyard, John found seven coins for his collection. \" \\\n",
    "\"If he already had nine coins, \" \\\n",
    "\"how many coins did John have after the new ones?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_eg = nlp(\"nine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nine NUM CD\n"
     ]
    }
   ],
   "source": [
    "print(doc_eg[0].text,doc_eg[0].pos_,doc_eg[0].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonTfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}