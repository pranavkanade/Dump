{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ''nlp\" is type of  \"spacy.en.English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"twice\")\n",
    "# print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twice ADV RB twice (300,)\n"
     ]
    }
   ],
   "source": [
    "for w in doc:\n",
    "    print(w.text, w.pos_, w.tag_, w.lemma_, w.vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "doc = nlp.make_doc(text)\n",
    "\n",
    "for proc in nlp.pipeline:\n",
    "    proc(doc)\n",
    "    \n",
    "nlp.pipeline  => {  doc = nlp.tokenizer(t),\\n\n",
    "                    nlp.tagger(doc),\\n\n",
    "                    nlp.parser(doc),\\n\n",
    "                    nlp.entity(doc) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreaded Pipe\n",
    "for sequence of documents use multithreading  \n",
    "### nlp.pipe(texts, batch_size=1000, n_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos and tags \n",
    "https://spacy.io/docs/usage/pos-tagging\n",
    "\n",
    "Entity types https://spacy.io/docs/usage/entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(doc.vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_1 = nlp(\"thrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73638170770354938"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.similarity(doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thrice'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1[0].is_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_2 = nlp(\"Joshua told his friend that his sister is nine years older than himself. If Joshua is nine at the moment, how old is his sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob1 = \"After digging in his backyard, John found seven coins for his collection. If he already had nine coins, how many coins did John have after the new ones?\"\n",
    "doc_1 = nlp(prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = []\n",
    "for span in doc_1.sents:\n",
    "    sent = ''.join(doc_1[i].string \n",
    "                   for i in range(span.start, span.end)).strip()\n",
    "    sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After digging in his backyard, John found seven coins for his collection.\n",
      "If he already had nine coins, how many coins did John have after the new ones?\n"
     ]
    }
   ],
   "source": [
    "for sentence in sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence tokenizing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After digging in his backyard, John found seven coins for his collection.\n",
      "If he already had nine coins, how many coins did John have after the new ones?\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_tokenize(prob1):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out droping all the nouns in the prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob1_without_noun = []\n",
    "\n",
    "for token in doc_1:\n",
    "    if (token.pos_ not in [\"NOUN\", \"PROPN\", \"DET\", \"PUNCT\", \"PRON\"]) and (token.tag_ not in [\"PRP$\", \"WP$\"]):\n",
    "        prob1_without_noun.append(token.orth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After', 'digging', 'in', 'found', 'seven', 'for', 'If', 'already', 'had', 'nine', 'how', 'many', 'did', 'have', 'after', 'new']\n"
     ]
    }
   ],
   "source": [
    "print(prob1_without_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_eg = nlp(\"nine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nine NUM CD\n"
     ]
    }
   ],
   "source": [
    "print(doc_eg[0].text,doc_eg[0].pos_,doc_eg[0].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonTfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}